**Project Abstract**

Additive manufacturing is a sophisticated technology generating and using a significant amount of data. The Common Data Dictionary (CDD) and Common Data Model (CDM) define the vocabulary and data models for AM data integration and exchange to improve the interoperability of AM data.

NIST has been working to newly develop the CDM, a formalized model for the CDD. Problematically, the definitions in the CDM may not completely follow the CDD standards. 

The purpose of this project is to review, test, and highlight these differences in order to improve the new model and enable interoperability.

Such a gap analysis is achieved through the development of a python tool that detects differences between the terminologies defined in the original CDD and the new CDM. In order to facilitate comparability between the two works, the pandas and JSON libraries are integrated into the python script. Meanwhile, the process explores themes of modularity, abstraction, and thematic-based mapping to enhance reusability of the code, thereby expanding its scope of application. The development of the program is assisted by the utilization of generative AI tools such as ChatGPT, a rapidly evolving resource.

The result is an automated procedure to compare data in different formats and capture their differences. The documentation of the inconsistencies provides insight into areas of weakness of the CDM and opportunities for revision to maximize interoperability of AM data.

**Experience**

One major takeaway from this project development process is that this framework will be critical for systems control by ensuring standardized data flow and enabling interoperability for systems integration.

While collaborating with an advanced team working on developing digital manufacturing processes, I received training and gained an understanding of additive manufacturing systems.
